# ================================================================
# üìå HOLDED INVOICES TRANSFORM SCRIPT 
# ================================================================
# This script transforms Holded invoices raw JSON into a clean,
# flattened tabular format for downstream analysis.
#
# üîπ INPUT:
#     - data/INPUT/holded_invoices/raw/holded_invoices_raw.json
#
# üîπ OUTPUT:
#     - data/INPUT/holded_invoices/clean/
#         ‚Ä¢ holded_invoices_clean.parquet
#         ‚Ä¢ holded_invoices_clean.csv
#         ‚Ä¢ holded_invoices_clean.json (optional debug toggle)
#
# üîπ Features:
#     - Flatten nested fields
#     - Timestamp conversion
#     - Clean list/dict-type columns
#     - Force fragile columns to string for compatibility
# ================================================================

import os
import json
import logging
import pandas as pd
import sys

# ============================================
# üîÅ TOGGLE JSON EXPORT (for debugging only)
# ============================================
SAVE_JSON = False

# ============================================
# ü™µ LOGGING SETUP
# ============================================

os.makedirs("logs", exist_ok=True)
logging.basicConfig(
    filename="logs/pipeline.log",
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)

# ============================================
# üîß TRANSFORMATION FUNCTION
# ============================================

def transform_holded_invoices():
    print("üö© Starting transform_holded_invoices()")
    logging.info("üö© Entered transform_holded_invoices()")

    try:
        input_path = "data/INPUT/holded_invoices/raw/holded_invoices_raw.json"
        output_dir = "data/INPUT/holded_invoices/clean"
        base_filename = "holded_invoices_clean"
        os.makedirs(output_dir, exist_ok=True)

        # ‚úÖ Load raw JSON
        print(f"üì• Loading data from {input_path}")
        with open(input_path, "r", encoding="utf-8") as f:
            raw_data = json.load(f)

        records = raw_data["data"] if isinstance(raw_data, dict) and "data" in raw_data else raw_data
        df = pd.json_normalize(records)

        if df.empty:
            msg = "‚ö†Ô∏è No invoice data found (empty DataFrame)."
            logging.warning(msg)
            print(msg)
            return

        # ‚úÖ Convert UNIX timestamps to datetime
        if "date" in df.columns:
            df["date"] = pd.to_datetime(df["date"], unit="s", errors="coerce")

        # ‚úÖ Detect and stringify list-type columns
        list_columns = [col for col in df.columns if df[col].apply(lambda x: isinstance(x, list)).any()]
        if list_columns:
            logging.warning(f"‚ö†Ô∏è List-type columns in Holded invoices: {list_columns}")
            print(f"‚ö†Ô∏è List-type columns in Holded invoices: {list_columns}")
            for col in list_columns:
                df[col] = df[col].apply(lambda x: str(x) if isinstance(x, list) else x)

        # ‚úÖ Detect and stringify dict-type columns
        dict_columns = [col for col in df.columns if df[col].apply(lambda x: isinstance(x, dict)).any()]
        if dict_columns:
            logging.warning(f"‚ö†Ô∏è Dict-type columns in Holded invoices: {dict_columns}")
            print(f"‚ö†Ô∏è Dict-type columns in Holded invoices: {dict_columns}")
            for col in dict_columns:
                df[col] = df[col].apply(lambda x: json.dumps(x) if isinstance(x, dict) else x)

        # ‚úÖ Coerce fragile columns to string (Parquet compatibility)
        force_string_columns = [
            "customId", "vatnumber", "type",
            "clientRecord", "supplierRecord", "groupId"
        ]
        for col in force_string_columns:
            if col in df.columns:
                df[col] = df[col].astype(str)

        # ‚úÖ Save as Parquet
        parquet_path = os.path.join(output_dir, base_filename + ".parquet")
        df.to_parquet(parquet_path, index=False)
        logging.info(f"‚úÖ Parquet saved to: {parquet_path}")
        print(f"‚úÖ Parquet saved to: {parquet_path}")

        # ‚úÖ Save as CSV
        csv_path = os.path.join(output_dir, base_filename + ".csv")
        df.to_csv(csv_path, index=False)
        logging.info(f"‚úÖ CSV saved to: {csv_path}")
        print(f"‚úÖ CSV saved to: {csv_path}")

        # ‚úÖ Optional: Save as JSON
        if SAVE_JSON:
            try:
                json_path = os.path.join(output_dir, base_filename + ".json")
                df.to_json(json_path, orient="records", indent=2)
                logging.info(f"‚úÖ JSON saved to: {json_path}")
                print(f"‚úÖ JSON saved to: {json_path}")
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è Could not save JSON: {e}")
                print(f"‚ö†Ô∏è Could not save JSON: {e}")

        logging.info(f"‚úÖ Total invoice records cleaned: {len(df)}")
        print(f"‚úÖ Total invoice records cleaned: {len(df)}")

    except Exception as e:
        logging.error(f"‚ùå Error transforming Holded invoices: {e}", exc_info=True)
        print(f"‚ùå Error transforming Holded invoices: {e}")
        sys.exit(1)

# ============================================
# üü¢ ENTRY POINT
# ============================================

if __name__ == "__main__":
    transform_holded_invoices()


